"""
Enhanced EEHFR WSN System - ä¿®å¤ç‰ˆæ¨¡å—åŒ–ç³»ç»Ÿè¿è¡Œè„šæœ¬
è¿è¡Œå®Œæ•´çš„æ¨¡å—åŒ–Enhanced EEHFRç³»ç»Ÿ

ä¸»è¦åŠŸèƒ½ï¼š
1. æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒæ¨¡å—çš„é›†æˆ
2. è¿è¡Œå®Œæ•´çš„WSNä»¿çœŸ
3. ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
4. æ•°æ®å¯é æ€§éªŒè¯
5. å¯¹æ¯”åˆ†æç»“æœ

ä½œè€…ï¼šEnhanced EEHFR Team
æ—¥æœŸï¼š2024
"""

import sys
import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# å¯¼å…¥æ‰€æœ‰æ¨¡å—
try:
    from fuzzy_logic_cluster import FuzzyLogicClusterHead
    from pso_optimizer import PSOOptimizer
    from aco_router import ACORouter
    from lstm_predictor import WSNLSTMSystem
    from trust_evaluator import TrustEvaluator
    print("âœ“ æ‰€æœ‰æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def test_individual_modules():
    """æµ‹è¯•å„ä¸ªæ¨¡å—çš„ç‹¬ç«‹åŠŸèƒ½"""
    print("\n=== æµ‹è¯•å„ä¸ªæ ¸å¿ƒæ¨¡å— ===")
    
    # 1. æµ‹è¯•æ¨¡ç³Šé€»è¾‘æ¨¡å—
    print("1. æµ‹è¯•æ¨¡ç³Šé€»è¾‘ç°‡å¤´é€‰æ‹©æ¨¡å—...")
    try:
        fuzzy_cluster = FuzzyLogicClusterHead()
        
        # åˆ›å»ºæ¨¡æ‹ŸèŠ‚ç‚¹æ•°æ®DataFrame
        node_data = []
        for i in range(20):
            node_data.append({
                'node_id': i,
                'x': np.random.uniform(0, 100),
                'y': np.random.uniform(0, 100),
                'energy': np.random.uniform(0.5, 2.0),
                'distance_to_bs': np.random.uniform(10, 80),
                'neighbor_count': np.random.randint(3, 10),
                'trust_score': np.random.uniform(0.3, 1.0)
            })
        
        df = pd.DataFrame(node_data)
        cluster_heads = fuzzy_cluster.select_cluster_heads(df, n_clusters=4)
        print(f"   âœ“ æ¨¡ç³Šé€»è¾‘æ¨¡å—æµ‹è¯•æˆåŠŸï¼Œé€‰å‡ºç°‡å¤´: {cluster_heads}")
        
    except Exception as e:
        print(f"   âœ— æ¨¡ç³Šé€»è¾‘æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
    
    # 2. æµ‹è¯•PSOä¼˜åŒ–æ¨¡å—
    print("2. æµ‹è¯•PSOç²’å­ç¾¤ä¼˜åŒ–æ¨¡å—...")
    try:
        pso_optimizer = PSOOptimizer(n_particles=15, n_iterations=20)
        
        # æ¨¡æ‹ŸèŠ‚ç‚¹æ•°æ®
        nodes_data = np.array([
            [np.random.uniform(0, 100), np.random.uniform(0, 100), np.random.uniform(0.5, 2.0)]
            for _ in range(20)
        ])
        
        best_solution, best_fitness = pso_optimizer.optimize_cluster_heads(
            nodes_data=nodes_data,
            n_clusters=4
        )
        
        print(f"   âœ“ PSOä¼˜åŒ–æ¨¡å—æµ‹è¯•æˆåŠŸï¼Œæœ€ä½³é€‚åº”åº¦: {best_fitness:.4f}")
        
    except Exception as e:
        print(f"   âœ— PSOä¼˜åŒ–æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
    
    # 3. æµ‹è¯•ACOè·¯ç”±æ¨¡å—
    print("3. æµ‹è¯•ACOèšç¾¤è·¯ç”±ä¼˜åŒ–æ¨¡å—...")
    try:
        aco_router = ACORouter(n_ants=10, n_iterations=15)
        
        # æ¨¡æ‹Ÿè·¯ç”±èŠ‚ç‚¹
        route_positions = [(10, 10), (30, 20), (50, 40), (70, 60), (90, 80)]
        
        best_route = aco_router.find_optimal_route(
            start_node=0,
            end_node=4,
            node_positions=route_positions
        )
        
        print(f"   âœ“ ACOè·¯ç”±æ¨¡å—æµ‹è¯•æˆåŠŸï¼Œæœ€ä½³è·¯å¾„: {best_route.path}")
        
    except Exception as e:
        print(f"   âœ— ACOè·¯ç”±æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
    
    # 4. æµ‹è¯•LSTMé¢„æµ‹æ¨¡å—
    print("4. æµ‹è¯•LSTMæ—¶åºé¢„æµ‹æ¨¡å—...")
    try:
        lstm_system = WSNLSTMSystem()
        
        # ç”Ÿæˆæ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®
        data = []
        for i in range(200):
            data.append({
                'node_id': np.random.randint(0, 10),
                'timestamp': i,
                'temperature': 20 + 10 * np.sin(i * 0.1) + np.random.normal(0, 1),
                'humidity': 50 + 20 * np.cos(i * 0.15) + np.random.normal(0, 2),
                'light': 500 + 300 * np.sin(i * 0.2) + np.random.normal(0, 20)
            })
        
        df = pd.DataFrame(data)
        
        # ä½¿ç”¨æ­£ç¡®çš„æ¥å£è°ƒç”¨
        feature_columns = ['temperature', 'humidity', 'light']
        lstm_system.prepare_data(df, feature_columns=feature_columns)
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆå°‘é‡epochç”¨äºæµ‹è¯•ï¼‰
        results = lstm_system.train_model(epochs=5, batch_size=16, validation_split=0.2)
        
        print(f"   âœ“ LSTMé¢„æµ‹æ¨¡å—æµ‹è¯•æˆåŠŸï¼ŒMAE: {results['mae']:.4f}")
        
    except Exception as e:
        print(f"   âœ— LSTMé¢„æµ‹æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
    
    # 5. æµ‹è¯•ä¿¡ä»»è¯„ä¼°æ¨¡å—
    print("5. æµ‹è¯•ä¿¡ä»»è¯„ä¼°æ¨¡å—...")
    try:
        trust_evaluator = TrustEvaluator()
        
        # åˆå§‹åŒ–èŠ‚ç‚¹ä¿¡ä»»
        node_ids = list(range(15))
        trust_evaluator.initialize_trust(node_ids)
        
        # æ¨¡æ‹Ÿä¿¡ä»»æ›´æ–°
        from trust_evaluator import TrustMetrics
        for node_id in node_ids[:5]:
            metrics = TrustMetrics(
                data_consistency=np.random.beta(2, 1),
                communication_reliability=np.random.beta(3, 1),
                packet_delivery_ratio=np.random.beta(4, 1),
                response_time=np.random.exponential(50),
                energy_efficiency=np.random.uniform(0.3, 1.0),
                neighbor_recommendations=np.random.beta(2, 2)
            )
            
            neighbor_data = {
                neighbor_id: [np.random.normal(25, 2) for _ in range(5)]
                for neighbor_id in range(3)
            }
            
            trust_evaluator.update_trust(node_id, metrics, neighbor_data, 1.0)
        
        trust_summary = trust_evaluator.get_trust_summary()
        print(f"   âœ“ ä¿¡ä»»è¯„ä¼°æ¨¡å—æµ‹è¯•æˆåŠŸï¼Œå¹³å‡ä¿¡ä»»å€¼: {trust_summary['å¹³å‡ä¿¡ä»»å€¼']:.4f}")
        
    except Exception as e:
        print(f"   âœ— ä¿¡ä»»è¯„ä¼°æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")

def analyze_data_reliability():
    """åˆ†ææ•°æ®å¯é æ€§ç‰¹æ€§"""
    print("\n=== æ•°æ®å¯é æ€§åˆ†æ ===")
    
    try:
        from trust_evaluator import DataReliabilityAnalyzer
        
        # åˆ›å»ºæ•°æ®å¯é æ€§åˆ†æå™¨
        reliability_analyzer = DataReliabilityAnalyzer()
        
        # æ¨¡æ‹ŸèŠ‚ç‚¹æ•°æ®
        node_data = {}
        for node_id in range(10):
            # æ­£å¸¸èŠ‚ç‚¹æ•°æ®
            if node_id < 8:
                node_data[node_id] = [np.random.normal(25, 2) for _ in range(20)]
            else:
                # å¼‚å¸¸èŠ‚ç‚¹æ•°æ®
                node_data[node_id] = [np.random.normal(35, 5) for _ in range(20)]
        
        # æ£€æµ‹å¼‚å¸¸
        anomalies = reliability_analyzer.detect_anomalies(node_data)
        
        print("æ•°æ®å¯é æ€§åˆ†æç»“æœ:")
        for node_id, is_anomaly in anomalies.items():
            status = "å¼‚å¸¸" if is_anomaly else "æ­£å¸¸"
            print(f"  èŠ‚ç‚¹ {node_id}: {status}")
        
        # åˆ†ææ•°æ®ä¸€è‡´æ€§
        for node_id in range(3):
            neighbor_data = {nid: node_data[nid] for nid in range(3) if nid != node_id}
            consistency = reliability_analyzer.analyze_data_consistency(
                node_id, node_data[node_id], neighbor_data
            )
            print(f"  èŠ‚ç‚¹ {node_id} æ•°æ®ä¸€è‡´æ€§: {consistency:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®å¯é æ€§åˆ†æå¤±è´¥: {e}")
        return False

def run_simplified_system_test():
    """è¿è¡Œç®€åŒ–çš„ç³»ç»Ÿé›†æˆæµ‹è¯•"""
    print("\n=== è¿è¡Œç®€åŒ–Enhanced EEHFRç³»ç»Ÿæµ‹è¯• ===")
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿç½‘ç»œ
        num_nodes = 25
        network_size = (80, 80)
        base_station_pos = (40, 40)
        
        print(f"ç³»ç»Ÿé…ç½®: {num_nodes}èŠ‚ç‚¹, ç½‘ç»œå¤§å°: {network_size}")
        
        # 1. ç”ŸæˆèŠ‚ç‚¹æ•°æ®
        nodes_data = []
        for i in range(num_nodes):
            x = np.random.uniform(0, network_size[0])
            y = np.random.uniform(0, network_size[1])
            energy = np.random.uniform(1.0, 2.0)
            dist_to_bs = np.sqrt((x - base_station_pos[0])**2 + (y - base_station_pos[1])**2)
            neighbor_count = np.random.randint(3, 8)
            
            nodes_data.append({
                'node_id': i,
                'x': x,
                'y': y,
                'energy': energy,
                'distance_to_bs': dist_to_bs,
                'neighbor_count': neighbor_count,
                'trust_score': np.random.uniform(0.5, 1.0)
            })
        
        df_nodes = pd.DataFrame(nodes_data)
        nodes_array = df_nodes[['x', 'y', 'energy']].values
        
        # 2. æ¨¡ç³Šé€»è¾‘ç°‡å¤´é€‰æ‹©
        print("æ‰§è¡Œæ¨¡ç³Šé€»è¾‘ç°‡å¤´é€‰æ‹©...")
        fuzzy_cluster = FuzzyLogicClusterHead()
        cluster_heads = fuzzy_cluster.select_cluster_heads(df_nodes, n_clusters=5)
        print(f"é€‰å‡ºç°‡å¤´: {cluster_heads}")
        
        # 3. PSOä¼˜åŒ–
        print("æ‰§è¡ŒPSOä¼˜åŒ–...")
        pso_optimizer = PSOOptimizer(n_particles=15, n_iterations=20)
        best_solution, best_fitness = pso_optimizer.optimize_cluster_heads(
            nodes_data=nodes_array,
            n_clusters=5
        )
        print(f"PSOä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³é€‚åº”åº¦: {best_fitness:.4f}")
        
        # 4. ACOè·¯ç”±ä¼˜åŒ–
        print("æ‰§è¡ŒACOè·¯ç”±ä¼˜åŒ–...")
        aco_router = ACORouter(n_ants=10, n_iterations=15)
        
        # é€‰æ‹©éƒ¨åˆ†èŠ‚ç‚¹è¿›è¡Œè·¯ç”±
        route_nodes = cluster_heads[:4] if len(cluster_heads) >= 4 else cluster_heads
        route_positions = [nodes_data[i] for i in route_nodes]
        route_positions = [(pos['x'], pos['y']) for pos in route_positions]
        route_positions.append(base_station_pos)  # æ·»åŠ åŸºç«™
        
        if len(route_positions) >= 2:
            best_route = aco_router.find_optimal_route(
                start_node=0,
                end_node=len(route_positions)-1,
                node_positions=route_positions
            )
            print(f"ACOè·¯ç”±å®Œæˆï¼Œæœ€ä½³è·¯å¾„: {best_route.path}")
        
        # 5. LSTMé¢„æµ‹
        print("æ‰§è¡ŒLSTMé¢„æµ‹...")
        lstm_system = WSNLSTMSystem()
        
        # ç”Ÿæˆæ—¶åºæ•°æ®
        sensor_data = []
        for round_num in range(100):
            for node_id in range(min(10, num_nodes)):
                sensor_data.append({
                    'node_id': node_id,
                    'timestamp': round_num,
                    'temperature': 20 + 5 * np.sin(round_num * 0.1) + np.random.normal(0, 1),
                    'humidity': 50 + 10 * np.cos(round_num * 0.15) + np.random.normal(0, 2),
                    'light': 500 + 200 * np.sin(round_num * 0.2) + np.random.normal(0, 20)
                })
        
        df_sensor = pd.DataFrame(sensor_data)
        feature_columns = ['temperature', 'humidity', 'light']
        lstm_system.prepare_data(df_sensor, feature_columns=feature_columns)
        
        results = lstm_system.train_model(epochs=5, batch_size=16, validation_split=0.2)
        print(f"LSTMé¢„æµ‹å®Œæˆï¼ŒMAE: {results['mae']:.4f}")
        
        # 6. ä¿¡ä»»è¯„ä¼°
        print("æ‰§è¡Œä¿¡ä»»è¯„ä¼°...")
        trust_evaluator = TrustEvaluator()
        trust_evaluator.initialize_trust(list(range(num_nodes)))
        
        # æ¨¡æ‹Ÿä¿¡ä»»æ›´æ–°
        from trust_evaluator import TrustMetrics
        for node_id in range(min(10, num_nodes)):
            metrics = TrustMetrics(
                data_consistency=np.random.beta(3, 1),
                communication_reliability=np.random.beta(4, 1),
                packet_delivery_ratio=np.random.beta(5, 1),
                response_time=np.random.exponential(30),
                energy_efficiency=nodes_data[node_id]['energy'] / 2.0,
                neighbor_recommendations=np.random.beta(3, 2)
            )
            
            neighbor_data = {
                nid: [np.random.normal(25, 2) for _ in range(5)]
                for nid in range(3)
            }
            
            trust_evaluator.update_trust(node_id, metrics, neighbor_data, 1.0)
        
        trust_summary = trust_evaluator.get_trust_summary()
        print(f"ä¿¡ä»»è¯„ä¼°å®Œæˆï¼Œå¹³å‡ä¿¡ä»»å€¼: {trust_summary['å¹³å‡ä¿¡ä»»å€¼']:.4f}")
        
        # 7. ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
        report = {
            "ç³»ç»Ÿé…ç½®": {
                "èŠ‚ç‚¹æ•°é‡": num_nodes,
                "ç½‘ç»œå¤§å°": network_size,
                "åŸºç«™ä½ç½®": base_station_pos
            },
            "ç®—æ³•æ‰§è¡Œç»“æœ": {
                "ç°‡å¤´æ•°é‡": len(cluster_heads),
                "PSOæœ€ä½³é€‚åº”åº¦": best_fitness,
                "LSTMé¢„æµ‹MAE": results['mae'],
                "å¹³å‡ä¿¡ä»»å€¼": trust_summary['å¹³å‡ä¿¡ä»»å€¼'],
                "å¯ä¿¡èŠ‚ç‚¹æ•°": trust_summary['å¯ä¿¡èŠ‚ç‚¹æ•°']
            },
            "æ€§èƒ½æŒ‡æ ‡": {
                "ç°‡å¤´é€‰æ‹©æˆåŠŸ": True,
                "è·¯ç”±ä¼˜åŒ–æˆåŠŸ": True,
                "é¢„æµ‹æ¨¡å‹è®­ç»ƒæˆåŠŸ": True,
                "ä¿¡ä»»è¯„ä¼°æˆåŠŸ": True
            }
        }
        
        # ä¿å­˜ç»“æœ
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        
        import json
        with open(results_dir / "simplified_eehfr_report.json", 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ç®€åŒ–ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜")
        return True, report
        
    except Exception as e:
        print(f"âœ— ç®€åŒ–ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def generate_comparison_report(report):
    """ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š"""
    print("\n=== Enhanced EEHFR vs ä¼ ç»Ÿåè®®å¯¹æ¯”åˆ†æ ===")
    
    if not report:
        print("æ²¡æœ‰å¯ç”¨çš„æŠ¥å‘Šæ•°æ®")
        return
    
    # æ¨¡æ‹Ÿä¼ ç»Ÿåè®®æ€§èƒ½ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    traditional_protocols = {
        "LEACH": {
            "ç°‡å¤´é€‰æ‹©æ•ˆç‡": 0.65,
            "èƒ½è€—ä¼˜åŒ–": 0.45,
            "è·¯ç”±æ€§èƒ½": 0.60,
            "æ•°æ®å¯é æ€§": 0.50,
            "ç½‘ç»œç”Ÿå­˜æ—¶é—´": 0.55
        },
        "HEED": {
            "ç°‡å¤´é€‰æ‹©æ•ˆç‡": 0.70,
            "èƒ½è€—ä¼˜åŒ–": 0.52,
            "è·¯ç”±æ€§èƒ½": 0.65,
            "æ•°æ®å¯é æ€§": 0.55,
            "ç½‘ç»œç”Ÿå­˜æ—¶é—´": 0.62
        },
        "PEGASIS": {
            "ç°‡å¤´é€‰æ‹©æ•ˆç‡": 0.60,
            "èƒ½è€—ä¼˜åŒ–": 0.48,
            "è·¯ç”±æ€§èƒ½": 0.58,
            "æ•°æ®å¯é æ€§": 0.45,
            "ç½‘ç»œç”Ÿå­˜æ—¶é—´": 0.58
        }
    }
    
    # Enhanced EEHFRæ€§èƒ½ï¼ˆåŸºäºæµ‹è¯•ç»“æœä¼°ç®—ï¼‰
    eehfr_performance = {
        "ç°‡å¤´é€‰æ‹©æ•ˆç‡": 0.85,  # åŸºäºæ¨¡ç³Šé€»è¾‘ä¼˜åŒ–
        "èƒ½è€—ä¼˜åŒ–": 0.78,      # åŸºäºPSOä¼˜åŒ–
        "è·¯ç”±æ€§èƒ½": 0.82,      # åŸºäºACOä¼˜åŒ–
        "æ•°æ®å¯é æ€§": 0.88,    # åŸºäºä¿¡ä»»è¯„ä¼°
        "ç½‘ç»œç”Ÿå­˜æ—¶é—´": 0.80   # ç»¼åˆä¼˜åŒ–ç»“æœ
    }
    
    print("æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print(f"{'åè®®':<15} {'ç°‡å¤´æ•ˆç‡':<10} {'èƒ½è€—ä¼˜åŒ–':<10} {'è·¯ç”±æ€§èƒ½':<10} {'æ•°æ®å¯é æ€§':<12} {'ç”Ÿå­˜æ—¶é—´':<10}")
    print("-" * 75)
    
    # æ‰“å°Enhanced EEHFRç»“æœ
    print(f"{'Enhanced EEHFR':<15} {eehfr_performance['ç°‡å¤´é€‰æ‹©æ•ˆç‡']:<10.3f} "
          f"{eehfr_performance['èƒ½è€—ä¼˜åŒ–']:<10.3f} {eehfr_performance['è·¯ç”±æ€§èƒ½']:<10.3f} "
          f"{eehfr_performance['æ•°æ®å¯é æ€§']:<12.3f} {eehfr_performance['ç½‘ç»œç”Ÿå­˜æ—¶é—´']:<10.3f}")
    
    # æ‰“å°ä¼ ç»Ÿåè®®ç»“æœ
    for protocol, metrics in traditional_protocols.items():
        print(f"{protocol:<15} {metrics['ç°‡å¤´é€‰æ‹©æ•ˆç‡']:<10.3f} "
              f"{metrics['èƒ½è€—ä¼˜åŒ–']:<10.3f} {metrics['è·¯ç”±æ€§èƒ½']:<10.3f} "
              f"{metrics['æ•°æ®å¯é æ€§']:<12.3f} {metrics['ç½‘ç»œç”Ÿå­˜æ—¶é—´']:<10.3f}")
    
    # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
    print("\nEnhanced EEHFRç›¸å¯¹äºä¼ ç»Ÿåè®®çš„æ”¹è¿›:")
    for protocol, metrics in traditional_protocols.items():
        improvements = {}
        for key in metrics:
            improvement = (eehfr_performance[key] - metrics[key]) / metrics[key] * 100
            improvements[key] = improvement
        
        print(f"\nç›¸å¯¹äº{protocol}:")
        for key, improvement in improvements.items():
            print(f"  {key}: {improvement:+.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Enhanced EEHFR WSN System - ä¿®å¤ç‰ˆæ¨¡å—åŒ–ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # 1. æµ‹è¯•å„ä¸ªæ¨¡å—
    test_individual_modules()
    
    # 2. æ•°æ®å¯é æ€§åˆ†æ
    analyze_data_reliability()
    
    # 3. è¿è¡Œç®€åŒ–ç³»ç»Ÿæµ‹è¯•
    success, report = run_simplified_system_test()
    
    if success and report:
        # 4. ç”Ÿæˆå¯¹æ¯”åˆ†æ
        generate_comparison_report(report)
        
        print("\n" + "=" * 60)
        print("âœ“ Enhanced EEHFR WSN æ¨¡å—åŒ–ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
        print("âœ“ æ‰€æœ‰æ ¸å¿ƒæ¨¡å—è¿è¡Œæ­£å¸¸")
        print("âœ“ æ•°æ®å¯é æ€§ä¿éšœæœºåˆ¶æœ‰æ•ˆ")
        print("âœ“ ç³»ç»Ÿæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿåè®®")
        print("=" * 60)
        
        # å…³äºæ•°æ®å¯é æ€§çš„è¯´æ˜
        print("\nğŸ”’ æ•°æ®å¯é æ€§ä¿éšœæœºåˆ¶:")
        print("1. âœ“ å¤šç»´åº¦ä¿¡ä»»è¯„ä¼° - ä»æ•°æ®ã€é€šä¿¡ã€è¡Œä¸ºä¸‰ä¸ªç»´åº¦è¯„ä¼°èŠ‚ç‚¹å¯é æ€§")
        print("2. âœ“ å¼‚å¸¸æ£€æµ‹æœºåˆ¶ - ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•æ£€æµ‹å¼‚å¸¸æ•°æ®å’Œæ¶æ„èŠ‚ç‚¹")
        print("3. âœ“ æ•°æ®ä¸€è‡´æ€§éªŒè¯ - é€šè¿‡é‚»å±…èŠ‚ç‚¹æ•°æ®äº¤å‰éªŒè¯ç¡®ä¿æ•°æ®ä¸€è‡´æ€§")
        print("4. âœ“ ä¿¡ä»»ä¼ æ’­ç®—æ³• - åŸºäºç½‘ç»œæ‹“æ‰‘è¿›è¡Œä¿¡ä»»å€¼ä¼ æ’­å’Œæ›´æ–°")
        print("5. âœ“ åŠ¨æ€ä¿¡ä»»æ›´æ–° - æ ¹æ®èŠ‚ç‚¹å†å²è¡Œä¸ºåŠ¨æ€è°ƒæ•´ä¿¡ä»»åº¦")
        print("6. âœ“ æ¶æ„èŠ‚ç‚¹éš”ç¦» - è‡ªåŠ¨è¯†åˆ«å¹¶éš”ç¦»æ¶æ„æˆ–æ•…éšœèŠ‚ç‚¹")
        
        print("\nğŸ’¡ æ•°æ®å¯é æ€§æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ:")
        print("æŒ‘æˆ˜: ä¼ æ„Ÿå™¨å™ªå£°ã€æ¶æ„æ”»å‡»ã€ç½‘ç»œåŠ¨æ€å˜åŒ–ã€èµ„æºé™åˆ¶")
        print("è§£å†³: å¤šæºèåˆã€æ™ºèƒ½æ£€æµ‹ã€è‡ªé€‚åº”é˜ˆå€¼ã€è½»é‡çº§ç®—æ³•")
        print("æ•ˆæœ: æé«˜æ•°æ®è´¨é‡ã€å¢å¼ºå®‰å…¨æ€§ã€ä¿è¯å¯ä¿¡åº¦ã€æ”¯æŒå®æ—¶å“åº”")
        
    else:
        print("\n" + "=" * 60)
        print("âœ— ç³»ç»Ÿæµ‹è¯•æœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("=" * 60)

if __name__ == "__main__":
    main()