import torch
import torch.nn as nn
import torch.optim as optim
import torch_geometric
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GCNConv, GraphSAGE, GATConv
import numpy as np
import networkx as nx

# --- 1. GNNæ¨¡å‹å®šä¹‰ ---
class ChainGNN(nn.Module):
    """ç”¨äºé¢„æµ‹æœ€ä¼˜é“¾å¼æ‹“æ‰‘çš„å›¾ç¥ç»ç½‘ç»œæ¨¡å‹"""
    def __init__(self, in_channels, hidden_channels, out_channels):
        super(ChainGNN, self).__init__()
        # å¯ä»¥é€‰ç”¨GCN, GraphSAGE, GATç­‰ä¸åŒå·ç§¯å±‚è¿›è¡Œå®éªŒå¯¹æ¯”
        self.conv1 = GATConv(in_channels, hidden_channels, heads=4, concat=True)
        self.conv2 = GATConv(hidden_channels * 4, hidden_channels, heads=2, concat=True)
        self.conv3 = GATConv(hidden_channels * 2, out_channels, heads=1, concat=False)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        
        x = torch.relu(self.conv1(x, edge_index))
        x = torch.relu(self.conv2(x, edge_index))
        
        # è¾“å‡ºå±‚ï¼šé¢„æµ‹æ¯ä¸ªèŠ‚ç‚¹ä¸å…¶é‚»å±…èŠ‚ç‚¹çš„è¿æ¥â€œå€¾å‘æ€§â€
        # è¿™é‡Œè¾“å‡ºçš„æ˜¯ä¸€ä¸ªä»£è¡¨è¿æ¥åˆ†æ•°çš„æ ‡é‡ï¼Œåˆ†æ•°è¶Šé«˜ä»£è¡¨è¶Šåº”è¯¥è¿æ¥
        x = self.conv3(x, edge_index)
        return x

# --- 2. è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨ ---
class WSNDataGenerator:
    """ç”Ÿæˆç”¨äºè®­ç»ƒGNNçš„WSNæ‹“æ‰‘æ•°æ®"""
    def __init__(self, num_nodes_range=(50, 100), area_size=(100, 100)):
        self.num_nodes_range = num_nodes_range
        self.area_size = area_size

    def _generate_random_wsn(self):
        """ç”Ÿæˆä¸€ä¸ªéšæœºçš„WSNç½‘ç»œæ‹“æ‰‘"""
        num_nodes = np.random.randint(*self.num_nodes_range)
        nodes = {
            i: (np.random.rand() * self.area_size[0], np.random.rand() * self.area_size[1])
            for i in range(num_nodes)
        }
        G = nx.random_geometric_graph(num_nodes, radius=25, pos=nodes)
        return G

    def _get_greedy_chain(self, G):
        """ä½¿ç”¨è´ªå¿ƒç®—æ³•ç”Ÿæˆæ¬¡ä¼˜é“¾ï¼ˆä½œä¸ºæ¨¡å‹çš„è¾“å…¥ç‰¹å¾ä¹‹ä¸€ï¼‰"""
        # æ­¤å¤„ç®€åŒ–å®ç°ï¼Œå®é™…åº”ä½¿ç”¨æ‚¨é¡¹ç›®ä¸­çš„build_energy_efficient_chainsé€»è¾‘
        if not G.nodes:
            return []
        path = nx.approximation.traveling_salesman_problem(G, cycle=False)
        return path

    def _get_optimal_chain(self, G):
        """é€šè¿‡å…¨å±€ä¼˜åŒ–ç®—æ³•ç”Ÿæˆæœ€ä¼˜é“¾ï¼ˆä½œä¸ºè®­ç»ƒæ ‡ç­¾ï¼‰"""
        # æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªNP-hardé—®é¢˜ï¼Œåªèƒ½å¯¹å°è§„æ¨¡ç½‘ç»œæ±‚è§£
        # å®é™…ç ”ç©¶ä¸­ï¼Œå¯ä»¥ä½¿ç”¨é«˜è´¨é‡çš„è¿‘ä¼¼è§£ï¼ˆå¦‚LKHç®—æ³•ï¼‰ä½œä¸ºâ€œæœ€ä¼˜â€æ ‡ç­¾
        if not G.nodes or len(G.nodes) > 15: # é™åˆ¶è§„æ¨¡ä»¥ä¿è¯å¯è®¡ç®—æ€§
            return self._get_greedy_chain(G)
        path = nx.approximation.traveling_salesman_problem(G, cycle=False, method=nx.approximation.christofides)
        return path

    def generate_dataset(self, num_samples=100):
        """ç”ŸæˆåŒ…å«å¤šä¸ªå›¾æ ·æœ¬çš„æ•°æ®é›†"""
        dataset = []
        for _ in range(num_samples):
            G = self._generate_random_wsn()
            if len(G.nodes) == 0:
                continue

            # èŠ‚ç‚¹ç‰¹å¾ï¼š[xåæ ‡, yåæ ‡, èŠ‚ç‚¹åº¦, èƒ½é‡ï¼ˆæ¨¡æ‹Ÿï¼‰]
            features = []
            for node in G.nodes():
                pos = G.nodes[node]['pos']
                degree = G.degree(node)
                energy = np.random.uniform(0.5, 1.0)
                features.append([pos[0], pos[1], degree, energy])
            x = torch.tensor(features, dtype=torch.float)

            # è¾¹ç´¢å¼•
            edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()

            # æ ‡ç­¾ï¼šæ„å»ºä¸€ä¸ªé‚»æ¥çŸ©é˜µè¡¨ç¤ºæœ€ä¼˜é“¾
            optimal_chain = self._get_optimal_chain(G)
            y = torch.zeros((len(G.nodes), len(G.nodes)))
            for i in range(len(optimal_chain) - 1):
                u, v = optimal_chain[i], optimal_chain[i+1]
                y[u, v] = y[v, u] = 1.0 # å¯¹ç§°çŸ©é˜µ

            data = Data(x=x, edge_index=edge_index, y=y)
            dataset.append(data)
        return dataset

# --- 3. è®­ç»ƒå’Œè¯„ä¼°æ¡†æ¶ ---
class GNNTrainer:
    """GNNæ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°å™¨"""
    def __init__(self, model, learning_rate=0.001):
        self.model = model
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        # ä½¿ç”¨BCEWithLogitsLossï¼Œå› ä¸ºå®ƒåœ¨æ•°å€¼ä¸Šæ›´ç¨³å®šï¼Œä¸”é€‚åˆå¤„ç†å›¾è¿æ¥é¢„æµ‹è¿™ç±»é—®é¢˜
        self.criterion = nn.BCEWithLogitsLoss()

    def train(self, train_loader, epochs=50):
        self.model.train()
        for epoch in range(epochs):
            total_loss = 0
            for data in train_loader:
                self.optimizer.zero_grad()
                
                # æ¨¡å‹é¢„æµ‹çš„æ˜¯èŠ‚ç‚¹çº§åˆ«çš„è¿æ¥åˆ†æ•°
                node_scores = self.model(data)
                
                # å°†èŠ‚ç‚¹åˆ†æ•°è½¬æ¢ä¸ºè¾¹çº§åˆ«çš„é¢„æµ‹
                # é€šè¿‡æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹åˆ†æ•°çš„ç‚¹ç§¯æ¥é¢„æµ‹è¾¹çš„å­˜åœ¨æ¦‚ç‡
                edge_pred = node_scores[data.edge_index[0]] * node_scores[data.edge_index[1]]
                edge_pred = torch.sum(edge_pred, dim=1)

                # å‡†å¤‡æ ‡ç­¾
                edge_label = data.y[data.edge_index[0], data.edge_index[1]]

                loss = self.criterion(edge_pred, edge_label)
                loss.backward()
                self.optimizer.step()
                total_loss += loss.item()
            
            avg_loss = total_loss / len(train_loader)
            print(f'Epoch {epoch+1:03d}, Loss: {avg_loss:.4f}')

    def predict_chain(self, wsn_graph):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ä¸ºæ–°çš„WSNå›¾é¢„æµ‹æœ€ä¼˜é“¾"""
        self.model.eval()
        with torch.no_grad():
            # ... (æ­¤å¤„çœç•¥å°†wsn_graphè½¬æ¢ä¸ºtorch_geometric.data.Dataçš„é€»è¾‘)
            # ... (ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹)
            # ... (æ ¹æ®é¢„æµ‹åˆ†æ•°ï¼Œä½¿ç”¨è´ªå¿ƒæˆ–æ³¢æŸæœç´¢ç­‰æ–¹æ³•è§£ç å‡ºæœ€ç»ˆçš„é“¾)
            pass
        print("é¢„æµ‹åŠŸèƒ½å¾…å®ç°...")

# --- 4. ä¸»ç¨‹åºå…¥å£ ---
if __name__ == '__main__':
    print("ğŸš€ 1. åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨...")
    data_generator = WSNDataGenerator()

    print("\nğŸš€ 2. ç”Ÿæˆè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†...")
    train_dataset = data_generator.generate_dataset(num_samples=200)
    test_dataset = data_generator.generate_dataset(num_samples=50)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32)

    print(f"\n   - ç”Ÿæˆäº† {len(train_dataset)} ä¸ªè®­ç»ƒæ ·æœ¬")
    print(f"   - ç”Ÿæˆäº† {len(test_dataset)} ä¸ªæµ‹è¯•æ ·æœ¬")

    print("\nğŸš€ 3. åˆå§‹åŒ–GNNæ¨¡å‹...")
    # è¾“å…¥ç‰¹å¾ç»´åº¦ä¸º4 (x, y, degree, energy)
    # è¾“å‡ºç»´åº¦ä¸º8ï¼Œä»£è¡¨ä¸€ä¸ª8ç»´çš„è¿æ¥å€¾å‘æ€§åµŒå…¥å‘é‡
    model = ChainGNN(in_channels=4, hidden_channels=32, out_channels=8)
    print(model)

    print("\nğŸš€ 4. å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    trainer = GNNTrainer(model)
    trainer.train(train_loader, epochs=50)

    print("\nğŸš€ 5. æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("   ä¸‹ä¸€æ­¥ï¼šå®ç°predict_chainæ–¹æ³•ï¼Œå¹¶å°†å…¶é›†æˆåˆ°æ‚¨çš„ä¸»ä»¿çœŸå¾ªç¯ä¸­ã€‚")