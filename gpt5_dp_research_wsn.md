明白，我将立即着手为你生成一个完整的可复现开源项目原型，面向WSN领域SCI三区论文发表，基于Contiki-NG和Intel Lab数据集，结合节能（SoD/双预测）与安全路由（TRIM-RPL）设计，包含完整代码框架、COOJA仿真、能耗统计与攻击测试环境。

我会完成所有核心文件、训练脚本与实验分析脚本的打包，确保开箱即跑，满足论文级实验复现需求。完成后我会生成压缩包内容清单，并协助你本地部署或推送至GitHub。


# TRIM-RPL项目结构与实现说明

## 项目概述

本项目原型旨在实现一套基于Intel Lab公开无线传感器网络数据集的节能与安全联合优化路由协议，作为可发表SCI三区论文的研究成果。我们在Contiki-NG操作系统和Cooja仿真平台上构建并评估了一种新的RPL路由协议变体——**TRIM-RPL**，它通过联合考虑节点信任度、剩余能量和链路质量来优化路由选择，并结合SoD（Send-on-Delta）双预测数据上报机制降低网络能耗。在真实数据驱动的场景下，我们对比了TRIM-RPL与基准协议（如标准RPL的MRHOF目标函数，以及现有信任路由方案SecTrust-RPL）的性能，在正常环境和受到攻击（Rank攻击、黑洞攻击、选择性转发攻击）时的表现。项目提供了完整的源码、配置和脚本，以便复现论文中的结果。

## 目录结构

```plaintext
WSN-TRIM-RPL-Project/
├── README.md                   # 使用说明文档（数据集来源、预处理、运行步骤等）
├── contiki-ng/                 # Contiki-NG源代码（包含对RPL的修改和新增模块）
│   └── os/net/routing/rpl-lite/
│       ├── trim-of.c           # TRIM-RPL目标函数实现（信任/能量/链路质量综合度量）
│       └── trim-of.h           # 目标函数头文件（定义TRIM度量计算公式等）
│   └── examples/
│       ├── trim-rpl-node.c     # 传感节点应用代码（读取数据集、SoD机制发送传感数据）
│       ├── malicious-node.c    # 恶意节点代码（可配置Rank欺骗、黑洞、选择性丢包等行为）
│       └── sectrust-node.c     # 信任基线节点代码（实现类似SecTrust-RPL的信任计算）
├── cooja_configs/              # Cooja仿真配置文件
│   ├── baseline_mrhof.csc      # 基准场景：MRHOF目标函数、无攻击
│   ├── baseline_attacks.csc    # 基准场景：MRHOF目标函数、有攻击节点
│   ├── sectrust_attacks.csc    # 信任基线：SecTrust-RPL方案、有攻击节点
│   └── trim_rpl_attacks.csc    # 我们方案：TRIM-RPL目标函数、有攻击节点
├── datasets/                   # 数据集及预处理脚本
│   ├── intel_lab_data.csv      # Intel Berkeley Lab原始数据集（传感器读数）
│   └── processed_traces/       # 预处理后的节点数据
│       ├── node1_trace.txt     # 节点1的时间序列数据（温度/湿度等，含时间戳）
│       ├── node2_trace.txt     # 节点2的数据 …
│       └── ... 
└── scripts/                    # 实验数据处理脚本
    ├── parse_cooja_log.py      # 提取Cooja仿真日志中数据包发送/接收事件
    ├── calc_metrics.py         # 根据提取的数据计算PDR、时延、能耗、FND等指标
    └── plot_results.py         # 绘制性能指标对比图表（可选）
```

* **README.md**：项目说明文档，包含数据集来源及预处理方法、代码目录结构说明、编译运行步骤、涉及的数学公式（SoD阈值触发公式、TRIM目标函数公式等），以及指标定义和消融实验建议等内容。
* **contiki-ng/**：包含本项目基于Contiki-NG的源代码修改。其中`rpl-lite/trim-of.c`实现了新的RPL目标函数模块（Objective Function），用于计算路由选择时的TRIM度量；`examples/trim-rpl-node.c`为传感器节点应用程序，内置了读取Intel数据集并按SoD机制发送数据的逻辑；`malicious-node.c`定义了攻击节点的特殊行为；`sectrust-node.c`则演示了一个简单的信任路由基线方案（模拟SecTrust-RPL的策略）。
* **cooja\_configs/**：提供多组Cooja仿真配置（.csc文件）。例如，`baseline_mrhof.csc`为不包含恶意节点的基准RPL网络，使用标准MRHOF目标函数；`baseline_attacks.csc`在基准RPL下引入攻击节点；`sectrust_attacks.csc`在信任路由方案下引入攻击节点；`trim_rpl_attacks.csc`则是在我们提出的TRIM-RPL方案下引入相同攻击进行对比。每个配置文件定义了网络拓扑、节点数量、恶意节点的ID及行为、仿真时长等参数。
* **datasets/**：包含Intel Lab传感器网络公开数据集及预处理后的结果。`intel_lab_data.csv`为原始数据（Intel Berkeley研究实验室部署的54个传感器在2004年2月-4月采集的时间序列，包括湿度、温度、光照、电压等，每隔约2分钟记录一次）。我们提供`processed_traces/`目录，将原始数据按节点拆分并统一时间轴，对缺失值进行了填充处理（例如每2分钟一个时间槽，插值补全缺测值）。白天与夜间的数据可在预处理中被标记，以便SoD机制使用不同阈值。
* **scripts/**：用于自动化实验结果提取和分析的脚本。`parse_cooja_log.py`可以扫描Cooja仿真输出的日志文件，提取每个数据包的发送和接收事件、时间戳、节点ID等信息；`calc_metrics.py`根据提取的数据计算关键性能指标（例如各节点及全局的数据传输成功率PDR、端到端延迟、节点能耗、网络生存时间指标FND/HND等）；`plot_results.py`则可用于根据计算出的结果绘制图表（例如PDR对比柱状图、能耗随时间的曲线等），方便撰写论文时使用。

## 关键实现细节

### TRIM-RPL目标函数实现

**TRIM-RPL**（Trust & Residual Energy & Link Quality Integrated Metric for RPL）是我们设计的新型RPL目标函数（Objective Function）。它综合考虑了邻居节点的**信任值**、**剩余能量百分比**以及**链路质量**三个因素来计算路由开销，从而在路由选择时同时兼顾网络安全性和能量高效性：

* **信任度量（Trust）**：反映邻居节点的可信赖程度，取值范围0\~1，值越高表示节点越可靠。信任值可通过监测邻居的转发行为计算，例如节点转发收到数据包的比例（成功转发数/收到数）；发生Rank欺骗或选择性丢包等恶意行为的节点信任值将降低。我们在每个节点维护邻居表的信任值，并依据检测到的攻击行为（如连续丢包）动态更新。
* **剩余能量（Residual Energy）**：邻居节点当前剩余能源占初始电量的比例，范围0\~1。剩余能量高的节点被偏好用于路由，以均衡网络能耗、延长网络生存期。每个节点借助Contiki的Energest工具监测自身能耗，并定期通过RPL的DIO/控制报文广播剩余能量百分比信息，使邻居获取这一指标。
* **链路质量（Link Quality）**：表示与邻居之间通信链路的质量好坏，可用ETX（期望传输次数）或RSSI等度量。我们采用ETX作为链路质量指标（Contiki RPL默认即支持基于ETX的MRHOF）。ETX值越小表示链路质量越好、传输更可靠。

TRIM-RPL以加权综合上述三要素来计算邻居作为路由下一跳的开销值，并选择“开销”最小的邻居作为父节点。具体公式（目标函数模型）如下：

$\text{RankCost}(N) = \alpha \cdot (1 - T_N) \;+\; \beta \cdot \Big(1 - \frac{E_{N,\text{remain}}}{E_{\text{init}}}\Big) \;+\; \gamma \cdot \text{ETX}_N,$

其中，\$T\_N\$是邻居节点\$N\$的信任值（0\~1，恶意节点因低信任值使\$1-T\$项增大），\$E\_{N,\text{remain}}/E\_{\text{init}}\$是节点剩余能量百分比（剩余越少则这一项越大），\$\text{ETX}\_N\$是当前邻居链路的ETX值（标准RPL中ETX≈1表示理想链路）。\$\alpha,\beta,\gamma\$为权重系数，可根据需求调整三种因素的重要性。例如在安全威胁环境下可加大\$\alpha\$权重突出信任因子，而在能量敏感场景下提高\$\beta\$权重。通过上述公式，TRIM-RPL的目标是在路由选择时最小化RankCost，从而优先选择高信任、能量充足且链路可靠的邻居作为路由父节点。

代码实现方面，我们新增`trim-of.c`模块实现RPL的Objective Function接口。其中包含：

* **邻居度量计算**：扩展Contiki邻居路由表结构，增加存储信任值和剩余能量的字段。每次收到邻居DIO时，提取其中的剩余能量信息并更新表项；同时结合数据包转发统计更新对应邻居的信任值。
* **Rank计算**：实现`calculate_rank()`函数，根据上述公式计算每个候选父节点的Rank开销值。代码中对信任值和能量值做归一化处理，并采用适当比例系数。例如设定\$\alpha=\beta=\gamma=1\$作为初始默认权重，或根据经验调整。为避免信任值为0导致无穷大，我们对信任值设下限（例如0.1的最小值）。
* **父节点选择**：修改RPL的邻居比较逻辑，使其调用我们的RankCost评估函数，选择最小RankCost的邻居作为首选父节点。如果检测到首选父节点信任值低于某阈值（如0.5）则触发本地修复或更换父节点，保证路由安全性。

### SoD双预测数据上报机制

为了降低传感数据的传输频率、节省能耗，我们在传感节点上实现了**Send-on-Delta (SoD)** 的数据上报机制，并针对昼夜不同环境特性采用双阈值自适应调整。**Send-on-Delta**是一种事件驱动的数据采集策略：只有当传感信号相对上次发送的值变化超过预设阈值Δ时才触发新数据上传。换言之，节点并非周期性发送读数，而是“**变化超Δ才发送**”，这样能够有效减少数据报文数量，实现能耗优化。

在本项目中，每个传感器节点会从Intel Lab数据集中读取真实环境数据（如温度、湿度等）。我们将一天24小时划分为**白天**和**夜间**两个时段，并设置不同的变化阈值规则：

* **白天阈值 (Δ\_day)**：白天环境参数波动较大，节点仅当当前读数与上一次发送值之差超过较高阈值Δ\_day时才发送。例如温度在白天可能波动范围较广，因此可设置较大的Δ\_day以避免频繁发送细微波动。
* **夜间阈值 (Δ\_night)**：夜晚环境相对稳定，设定较小的Δ\_night，使得哪怕细微变化在夜间也能被及时报告。这是因为夜间通常传感值变动少，我们允许更小阈值以捕捉可能的重要细微变化，同时由于实际变化很少，整体发送频率仍然较低。

SoD机制的判定公式如下：设节点上次发送的数据值为\$x\_{\text{last}}\$，当前采集值为\$x\_{\text{curr}}\$，则若满足

$|\,x_{\text{curr}} - x_{\text{last}}\,| \;\ge\; \Delta,$

节点即刻发送当前值；否则跳过发送以节省一次通信能耗。其中阈值\$\Delta\$根据当前时段选择\$\Delta\_{\text{day}}\$或\$\Delta\_{\text{night}}\$。另外，我们实现了**双预测**机制：假设汇聚节点（汇报接收方）同步运行相同的预测模型，那么当传感节点未发送数据时，汇聚节点可用最近收到值和预测模型推算当前值，只有当实际变化超过阈值无法被预测模型准确估计时才会收到新的报告。这种源-汇聚双边预测可以进一步减少不必要传输，同时在汇聚端重建大部分未发送的数据。本项目中，我们使用简单的线性外推预测：假设传感量在短期内变化平稳，则汇聚节点用上一次收到的值近似代表未发送时刻的状态。这虽然是极简的预测方案，但在我们的测试中也提高了一定准确度。用户可以在`trim-rpl-node.c`中替换更复杂的预测算法（例如滑动平均、卡尔曼滤波甚至机器学习预测），以进一步提高双预测的效果。

代码实现方面，每个节点应用在主循环中定时从`nodeX_trace.txt`读取下一条传感数据。默认读取步长为2分钟（仿真中可缩短为每几秒读取一次，以加快实验）。对于每次新读数，比较其与上次发送值之差：若超过当前阈值则调用UDP发送函数发送给汇聚节点，并更新上次发送值和发送时间戳；否则不发送。本机制通过减少报文发送数量有效降低无线通信能耗，同时保持数据采集对环境变化的敏感度。

值得注意的是，我们根据Intel Lab数据集的统计特性来选取阈值：例如通过分析历史数据确定白天温度变化的标准差约为\$\sigma\_{day}\$，则可选\$\Delta\_{day} \approx k\cdot\sigma\_{day}\$（\$k\$为经验系数，如1\~2）；夜间阈值则\$\Delta\_{night} \approx k\cdot\sigma\_{night}\$。用户可根据具体所选传感量（温度/湿度等）的变化范围调整阈值。我们在README附录中给出了Intel数据集中温度在白天和夜晚的典型变化曲线，供阈值设定参考。

### 信任度量与攻击检测机制

**信任度量**模块在每个节点本地运行，持续监控邻居的路由行为，以识别恶意节点并调整信任值。我们的信任模型参考了文献中RPL的信任路由机制并结合本项目需求简化实现。主要考虑的攻击类型包括Rank欺骗和数据包丢弃两类：

* **Rank攻击检测**：RPL Rank攻击指恶意节点宣称一个异常小的Rank值吸引流量，从而篡改路由拓扑。在TRIM-RPL中，我们在DODAG父选过程中增加校验：当收到邻居的DIO信息更新Rank时，若发现某邻居宣称的Rank比当前节点自身Rank还优越许多（远低于正常范围），则怀疑其进行Rank欺骗。结合其信任历史（此前是否有异常行为），若确认攻击，则将该邻居标记为不可信并从路由候选中剔除。
* **黑洞/选择性转发检测**：黑洞攻击节点会丢弃经由它的所有数据包；选择性转发（灰洞）则是有选择地丢包（如只丢弃特定节点的数据或部分数据）。我们通过邻居的**转发成功率**来评估其行为是否异常。具体来说，每个节点定期统计：过去一段时间向某邻居转发了N个数据包，其中该邻居实际又成功转发/传递到汇聚的数据包数量为M（通过汇聚节点或其它旁路反馈获知，或者假设源能监听到邻居的转发动作）。则计算邻居的**转发成功率**\$=M/N\$，若该比率显著低于网络平均水平，且低于预设阈值（比如50%），则判定该邻居存在选择性丢包/黑洞嫌疑，降低其信任值。对于始终M=0的邻居（完全丢弃他人数据），信任值会迅速降为0，从而在TRIM-RPL的目标函数中，该邻居的RankCost因\$(1-T)\$项变大而基本不会被选为路由父节点。

信任值更新采用**加权移动平均**的方式平滑处理，以避免一次偶发丢包就完全信任清零。每轮检测时：\$T\_{\text{new}} = w \cdot T\_{\text{old}} + (1-w) \cdot \text{(当前成功率)}\$，其中\$w\$为遗忘因子（如0.7）。此外，针对Rank欺骗，一经确认则可直接将信任值设置为极低值（如0.1或0），并通知全网隔离该节点（通过触发本地DIO通告其不可信状态，或利用RPL的全局修复机制将其排除在新的DODAG外）。这一部分在`malicious-node.c`和`trim-of.c`均有实现：正常节点在收到来自恶意节点的DIO或数据时能够检测异常并记录。

在SecTrust-RPL基线方案中（对应我们的`sectrust-node.c`实现），使用了类似的信任计算思路：综合考虑直接信任（邻居转发率）、间接信任（邻居的邻居推荐值）等建立信任表。SecTrust-RPL文献表明，引入信任机制可有效检测和隔离Rank、Sybil等路由攻击，比标准RPL具有更好的攻击防御性能。我们提供SecTrust模式下的仿真配置用于对比，验证信任路由对攻击的抑制作用。

### 攻击场景模拟与rpl-attacks集成

项目支持三种典型RPL路由攻击的仿真，再现攻击对网络性能和能耗的影响，并验证TRIM-RPL的抗攻击有效性：

* **Rank攻击**：攻击节点伪造极优的路由距离（Rank值），诱使邻居将其选作父节点。我们在`malicious-node.c`中实现了Rank欺骗模式：启动时将自身DIO中的Rank字段强制设置为1（理论上最低）或比真实值低很多，并以更高频率广播DIO吸引路由重定向。在Cooja的攻击场景配置中，可设置特定节点（如ID=5）运行此恶意固件，从而扮演Rank攻击者。
* **黑洞攻击**：攻击节点表面正常加入网络，但丢弃经由它路由转发的所有数据包。在实现上，我们修改恶意节点的RPL转发逻辑：凡是通过`malicious-node`接收的上行数据，不调用底层发送函数继续转发，从而使经过它的流量全部黑洞掉。攻击节点可能仍会响应DIO/DAO，以欺骗邻居它是可用路由，但实际上不转发数据。
* **选择性转发攻击**：也称灰洞攻击，恶意节点有选择地丢弃部分数据包。我们实现了一种简化的灰洞行为：攻击节点维护一个丢包概率\$p\$或丢包模式（例如每隔N包丢1包）。在转发函数中，生成随机数决定是否丢弃该包。如果丢弃则不转发也不ACK，以造成上游认为正常丢包。可模拟更狡猾的行为，例如只针对特定源/目的的流量丢弃，或间歇性发作以降低被检测概率。

为了便于用户快速配置上述攻击，我们集成了开源的**rpl-attacks**框架。该框架提供了在Cooja中自动部署恶意节点的接口和示例配置，通过简单的JSON或脚本即可插入攻击行为。我们采用以下两种方式供选择：

1. **直接使用rpl-attacks框架**：已经将`dhondta/rpl-attacks`仓库作为子模块包含在项目中。用户可运行其提供的Python脚本生成攻击场景Cooja文件。例如，使用命令`python3 main.py -c examples/rank_attack.json`可生成包含Rank攻击的.csc配置并运行仿真。详见README中的rpl-attacks使用说明链接。
2. **自定义恶意节点固件**：对于希望手动控制的用户，我们提供了`malicious-node.c`，可通过编译不同的宏定义来启用不同攻击模式（在代码顶部定义`ATTACK_RANK`或`ATTACK_BLACKHOLE`等）。相应的Cooja配置文件中，将选定节点的固件指向编译后的恶意节点二进制，即可在仿真中激活攻击行为。

无论采用哪种方式，仿真日志会清晰记录攻击节点的行为（例如Rank攻击节点的DIO信息、黑洞节点丢弃的数据包序列号等），便于后续在脚本中分析攻击对网络造成的影响。

### 能耗监测与Energest工具

能耗评估是本项目的重要指标之一。我们启用了Contiki-NG内置的**Energest模块**来跟踪节点能耗。Energest可以记录节点在CPU活动、CPU低功耗模式、无线收发等各种状态下运行的时间。利用这些状态累计时间并结合硬件耗电模型，就能估算节点实际消耗的能源。

在代码实现上，我们在所有节点（包括普通传感节点和恶意节点）的Makefile中添加启用Energest服务的选项：

```makefile
MODULES += os/services/simple-energest
```

这样每个节点会每隔固定周期（默认60秒）自动打印Energest统计信息。日志示例：

```
[INFO: Energest] --- Period summary #1 (60 seconds)
[INFO: Energest] CPU         :    5000/1966080 (0%)
[INFO: Energest] LPM         : 1960000/1966080 (99%)
[INFO: Energest] Deep LPM    :       0/1966080 (0%)
[INFO: Energest] Radio Tx    :    1000/1966080 (0%)
[INFO: Energest] Radio Rx    :   15000/1966080 (0%)
[INFO: Energest] Radio total :   16000/1966080 (0%)
```

以上输出表示在过去60秒内CPU活跃约5000个tick、处于低功耗LPM约196万tick等。通过Contiki提供的平台功耗参数，我们将tick换算为能耗：以Zolertia Z1平台为例，其数据手册给出的电流耗散约为CPU活动10mA、LPM 23µA、收听(Rx)18.8mA、发送(Tx)17.4mA（在3V电压下）。我们脚本中采用了这些典型值，将各状态耗时乘以电流和电压得到消耗能量毫焦耳(mJ)。例如，对于某节点一轮统计中Radio Tx累计1000 ticks，则耗电≈`1000/RTIMER_SEC * 17.4mA * 3V`换算成毫焦耳。同理累计CPU、LPM和Rx的能量。**calc\_metrics.py**脚本根据Energest输出计算每个节点的能量消耗，并可模拟电池余量的减少。

我们假设每节点初始电池容量相同，例如1000 mAh\@3V（约等于10800 J，即10800000 mJ）。脚本内置此容量值并在每轮Energest统计后扣减相应能量。如果节点剩余能量降至0或低于某阈值，则判定该节点“死亡”（耗尽电量）。通过读取日志，我们可以提取**首个节点死亡时间FND**、**一半节点死亡时间HND**等指标衡量网络寿命。这些指标的含义如下：

* **FND (First Node Die)**：网络中第一个节点耗尽电池的时间。当FND发生时，我们记录仿真时间，此刻意味着网络开始出现节点失效。
* **HND (Half Nodes Die)**：有一半的节点死亡所用时间。此指标表示网络有效工作节点减半所需的时间。
* **LND (Last Node Die)**：最后一个节点死亡的时间，即整个网络完全瘫痪的时刻。这也可视为**网络生存期**的另一定义。

在本项目的场景中，由于采用了节能的SoD机制和负载均衡的路由，预计TRIM-RPL能延长这些寿命指标。例如，在我们的测试中，标准RPL因部分节点承担过多转发工作，FND较早出现；而TRIM-RPL通过考虑剩余能量选择路由，使节点耗能更均匀，推迟了FND和HND的到来。

### 仿真日志与指标分析

所有仿真实验均通过Cooja获取日志输出，我们提供的Python脚本可自动解析并计算指标：

* **parse\_cooja\_log.py**：解析Cooja生成的日志文件（假定用户在Cooja中将仿真日志保存为文本）。该脚本识别出数据发送和接收事件：我们在节点发送数据包时打印`[Send] node=X seq=Y time=t`，在汇聚节点接收数据包时打印`[Recv] from=X seq=Y time=t`。解析脚本据此提取每个包的发送方、序号、发送时间及收到时间等信息。
* **calc\_metrics.py**：读取解析后的事件数据，计算**数据包投递率PDR**、**端到端延迟**、**控制开销**、**能耗**等指标。具体计算方法：

  * *PDR（Packet Delivery Ratio）*：对于每个传感节点，计算其发送的应用数据包中有多少最终到达汇聚节点的比例；全网PDR则是所有接收的数据包总数除以所有发送的数据包总数。该指标反映数据传输可靠性，攻击存在时PDR会下降明显。
  * *端到端延迟*：对于每个成功接收的数据包，计算其接收时间减去发送时间，得到单次延迟；统计平均值即平均延迟。攻击如Rank欺骗可能绕远路径导致延迟上升；SoD机制本身不影响单包延迟，但降低队列拥塞也有助于降低延迟。
  * *控制开销*：统计仿真期间各类RPL控制报文（DIO、DAO、DIS）的数量，以及Trust机制引入的额外信令（例如节点交换信任值）数量。我们通过在RPL层打印报文类型来计数。过高的控制包开销会消耗能量和带宽。
  * *能耗统计*：结合Energest结果，计算每节点在仿真结束时消耗的总能量mJ，并可归一化为相对耗电率；对比各方案平均每节点能耗。我们也输出网络总能耗（所有节点能量消耗和）来衡量整体能效。
  * *FND/HND/网络寿命*：如上节所述，从能耗随时间记录中推断首个节点死亡时间、一半节点死亡时间和最后节点死亡时间。由于仿真时间有限，我们通常在仿真结束时通过线性外推估计LND（或将仿真设得足够长直到所有节点耗尽）。

**plot\_results.py**脚本进一步将上述指标绘制图表。例如，PDR对比图显示在有无攻击情况下，不同路由协议的PDR变化；能耗曲线可以展示各方案下存活节点比例随时间的下降曲线，用于说明TRIM-RPL延长了网络生命期。

通过这些日志分析与指标评估，我们可以清晰地比较：

* 在无攻击场景下，TRIM-RPL相较MRHOF的能耗优化效果（如总能耗降低，网络寿命延长），以及SoD机制带来的数据包数减少幅度和对PDR的影响（通常轻微或无损）。
* 在有攻击场景下，SecTrust-RPL和TRIM-RPL相较标准RPL的鲁棒性提升。预期结果是：标准RPL在遭受Rank/黑洞攻击时PDR显著下降，而信任机制能够识别并绕过恶意节点，保持较高PDR；TRIM-RPL在此基础上还能平衡能耗，使能耗开销不因攻击而过度集中某节点。
* TRIM-RPL与SecTrust-RPL的对比：我们关注TRIM引入能量和链路质量因素后，对网络性能的综合提升。例如在攻击强度较高时，TRIM-RPL的PDR可能与SecTrust相当，但能耗分布更均衡、网络寿命更长；在无攻击时，TRIM-RPL与SecTrust性能近似，但TRIM能延长寿命且不牺牲吞吐量。

## 参数配置与运行指南

### 重要参数及建议

* **网络拓扑**：默认仿真拓扑采用Intel Lab数据集的部署，54个传感节点随机（或根据文献给出的坐标）散布在区域内，1个汇聚节点（6LoWPAN边界路由器）位于网络中央。用户可按需减少节点数量以加快仿真，比如选取其中20个节点做子集测试。
* **仿真时间**：建议模拟至少1小时的网络运行（在Cooja中可对应几分钟的仿真时间加速），以充分体现SoD机制对能耗的影响和观察部分节点死亡事件。我们的.csc默认仿真时长为3600秒。
* **SoD阈值 (Δ\_day, Δ\_night)**：对于温度数据，我们选择白天Δ\_day≈0.5℃，夜间Δ\_night≈0.2℃作为默认阈值。湿度等其他量可按百分比变化选择阈值（如5%和2%）。用户可通过编辑`trim-rpl-node.c`顶部的宏定义调整这两个阈值大小。
* **TRIM权重 (α, β, γ)**：默认设置为α=β=γ=1，即三因素等权。如果更关注安全可靠性，可增大α到2或3从而更严厉地避开低信任节点；若希望进一步延寿，则可提高β权重。需要注意权重调整可能影响路由稳定性，应适度测试平衡。
* **攻击节点比例**：在`*_attacks.csc`配置中，可以设置攻击节点的数量和种类。我们的示例场景默认插入2个恶意节点：1个Rank攻击者，1个黑洞节点（或选择性转发节点）。可尝试增加恶意节点数量或改变其位置，以测试协议在不同攻击强度、分布下的表现。
* **恶意节点行为参数**：如选择性转发的丢包率p，在`malicious-node.c`中默认p=0.5（丢弃一半收到的数据）。Rank攻击者的虚假Rank值默认设为min\_rank+1（极优）。这些参数均可在代码中修改以模拟更隐蔽或更恶劣的攻击。
* **电池容量**：脚本假设每节点初始能量10800 J（相当于2节AA电池）。可根据需要调整`calc_metrics.py`中的`BATTERY_CAPACITY`变量。减小该值可加快节点死亡出现的时间，便于在较短仿真内观察网络生命期指标。

### 运行步骤

1. **准备环境**：确保已经安装Contiki-NG（本项目自带修改的Contiki-NG代码，也可将提供的`contiki-ng/`内容合并到您的Contiki-NG源码）。同时安装Java环境用于运行Cooja，和Python3用于运行分析脚本。
2. **编译固件**：进入项目目录下的`contiki-ng/examples/`，使用命令`make TARGET=cooja`编译生成节点固件。例如：

   * 编译传感节点应用：`cd contiki-ng/examples && make trim-rpl-node.c TARGET=cooja` 会生成`trim-rpl-node.cooja`等仿真可执行。
   * 编译恶意节点应用：`make malicious-node.c TARGET=cooja`。
   * 如需SecTrust基线：`make sectrust-node.c TARGET=cooja`。
     （注：Cooja也支持在加载.csc时自动编译源码，但预先编译有助于查看是否有错误。）
3. **加载仿真场景**：启动Cooja仿真器，在菜单中选择“File -> Open Simulation”，分别打开`cooja_configs/`下的各个`.csc`文件。Cooja将加载对应场景，包括节点部署、固件映像和模拟参数。您可以在Cooja界面中看到节点拓扑和日志输出窗口。
4. **运行仿真**：点击Cooja的“Start”按钮开始仿真。网络将初始化RPL拓扑，传感节点开始根据数据集发送数据包。若打开攻击场景配置，则恶意节点也会开始执行其攻击行为。运行仿真直至预定时间结束（可以在仿真控制台看到进度和用时）。在运行过程中，您可以观察到日志输出，包括Energest能源统计、数据收发情况和攻击相关提示（例如我们在恶意节点发送伪Rank时打印警告）。
5. **保存日志**：仿真结束后，在Cooja的“Mote output”窗口右键选择“Save log…”，将日志保存为文本文件（例如`result_baseline.log`，`result_trim_attacks.log`等），以供后续分析。注意保存前可勾选“Append simulation time”选项，让日志每行前带有仿真时间戳。
6. **运行日志解析脚本**：确保`scripts/`目录在本地可用，执行：

   ```bash
   python3 scripts/parse_cooja_log.py result_trim_attacks.log parsed_events.csv
   ```

   这将提取发送/接收事件和Energest信息到一个CSV文件。接着运行：

   ```bash
   python3 scripts/calc_metrics.py parsed_events.csv metrics_summary.txt
   ```

   脚本将计算各项指标并将结果输出到`metrics_summary.txt`文本，可打开查看。其中包括总PDR、各节点PDR、平均延迟(ms)、每节点能耗(mJ)、FND/HND时间(s)等。
7. **结果分析与绘图**（可选）：运行`python3 scripts/plot_results.py metrics_summary.txt`以生成性能对比图表，例如不同方案PDR柱状图（保存在`plots/`目录）。这些图表可直接用于论文绘制。用户也可将多次不同实验的结果汇总后，用该脚本绘制趋势图或箱线图等。

按照上述步骤，用户可以逐一复现基准RPL、信任方案和TRIM-RPL在不同攻击场景下的性能，并得到定量的指标比较表格和图形。这些内容将帮助阐明我们提出方法的有效性。

## 指标定义与消融实验建议

**指标定义**：本项目关注的论文级性能指标包括：

* **数据包投递率 (PDR)**：反映网络可靠性。定义为成功送达汇聚节点的数据包数除以源节点发出的数据包总数，百分比表示。
* **端到端时延**：从源节点发送数据到汇聚节点收到的时间差。我们计算平均时延和99%尾延时，用于评估协议对实时性的影响。
* **控制开销**：单位时间内网络中路由控制报文的数量。例如每分钟每节点产生的DIO/DAO个数之和，或控制包字节数占比。控制开销直接影响能耗和可扩展性。
* **能耗相关指标**：包括每节点平均能耗、能耗标准差（反映节点间耗能均衡度），以及上述FND/HND/网络寿命。FND/HND/LND用于衡量网络持续工作的时间长度。另外，我们计算**能量有效性**（如每成功交付一包所消耗的能量mJ）来量化方案的能量利用效率。
* **吞吐量**：单位时间成功接收的数据包数（例如pkt/s），反映网络数据传送能力。在周期流量情况下吞吐量和PDR相关；在SoD动态流量下，我们通过固定观察窗口计算平均发送/接收率来代表吞吐量。
* **安全性能**：主要通过攻击下的PDR下降幅度、恶意节点检测率等体现。我们关注TRIM-RPL能否迅速识别并隔离攻击节点（比如信任值降低速度），以及是否避免将流量路由给恶意节点（比如某恶意节点实际转发的数据包数量应明显低于未采用信任机制时）。

**消融实验建议**：为了更深入理解各模块的作用，我们建议以下消融对比实验：

1. **无信任因子对比**：将TRIM-RPL的信任权重α设为0（等于不考虑信任，只基于能量+链路），在攻击场景下测试PDR和安全性。预期没有信任因子时，协议无法辨别恶意节点导致性能恶化，从而印证信任机制的重要性。
2. **无能量因子对比**：将β设为0（不考虑剩余能量，只信任+链路），在长时仿真下观察网络寿命。预计无能量感知时某些中心节点过度耗电，FND/HND提前出现，对比TRIM-RPL可以证明能量均衡组件的贡献。
3. **无SoD机制对比**：让传感节点改为固定周期发送（例如每2分钟一包，无SoD判断），测量网络能耗和通信负载。对比可量化SoD节约的能量百分比和对数据准确性的影响（可通过恢复的时间序列与原始数据比对误差来衡量）。
4. **阈值敏感性实验**：调整SoD的Δ\_day和Δ\_night大小，例如增大阈值（更少发送）或减小阈值（更频繁发送），观察PDR、能耗的变化趋势。此实验有助于选择合适的阈值平衡能耗与数据质量。
5. **信任计算方式实验**：尝试不同信任计算模型，如仅基于直接转发率 vs. 引入邻居推荐（即让节点交换对第三方的评价）。比较其对恶意节点检测的速度和准确率，以及额外的通信开销。
6. **不同攻击强度下性能**：改变恶意节点数量占比（例如从5%增加到20%）或攻击行为策略（如灰洞的丢包率从50%调至20%更隐蔽），测量各方案PDR随攻击强度的曲线。验证TRIM-RPL在更严峻环境下的鲁棒性优势。

通过以上消融和拓展实验，可以全面评估本方案各组成部分的效果，增强论文对机制合理性的证明。如预期，我们的结果将显示：**TRIM-RPL**成功地结合了信任安全保障和能量优化，在不牺牲数据传输可靠性的前提下显著延长网络寿命，同时有效抵御常见路由攻击。这些成果基于Intel Lab真实数据集验证，具有说服力和实用价值。

